{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dwh.cfg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npd.DataFrame({\"Param\":\\n                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\\n              \"Value\":\\n                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\\n             })\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AWS_ACCESS_KEY_ID      = config.get('AWS','AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY  = config.get('AWS','AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "IAM_ROLE_NAME      = config.get('IAM_ROLE', \"IAM_ROLE_NAME\")\n",
    "\n",
    "\n",
    "#CLUSTER_TYPE       = config.get(\"CLUSTER\",\"DWH_CLUSTER_TYPE\")\n",
    "#DWH_NUM_NODES          = config.get(\"CLUSTER\",\"DWH_NUM_NODES\")\n",
    "#NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "CLUSTER_IDENTIFIER = config.get(\"CLUSTER\",\"CLUSTER_IDENTIFIER\")\n",
    "DB_NAME            = config.get(\"CLUSTER\",\"DB_NAME\")\n",
    "DB_USER            = config.get(\"CLUSTER\",\"DB_USER\")\n",
    "DB_PASSWORD        = config.get(\"CLUSTER\",\"DB_PASSWORD\")\n",
    "DB_PORT               = config.get(\"CLUSTER\",\"DB_PORT\")\n",
    "\n",
    "\n",
    "\n",
    "#(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "'''\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":\n",
    "                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "ec2 = boto3.resource('ec2',\n",
    "                       region_name=\"us-east-1\",\n",
    "                       aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                       aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    "                    )\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-east-1\",\n",
    "                       aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                       aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    "                   )\n",
    "\n",
    "iam = boto3.client('iam',aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                     aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "                     region_name='us-east-1'\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-east-1\",\n",
    "                       aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                       aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "1.2 Attaching Policy\n",
      "1.3 Get the IAM role ARN\n"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#1.1 Create the IAM role, \n",
    "try:\n",
    "    print(\"1.1 Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"1.3 Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "#print(roleArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "        response = redshift.create_cluster(\n",
    "            #HW\n",
    "            \n",
    "            ClusterType='multi-node',\n",
    "            NumberOfNodes=4,\n",
    "            NodeType='dc2.large',\n",
    "            #PubliclyAccessible=True,\n",
    "            \n",
    "            #Identifiers & Credentials\n",
    "            DBName=DB_NAME,\n",
    "            MasterUsername=DB_USER,\n",
    "            MasterUserPassword=DB_PASSWORD,\n",
    "            ClusterIdentifier=CLUSTER_IDENTIFIER,\n",
    "            #Port=config.getint('CLUSTER', 'DB_PORT'),\n",
    "            \n",
    "            #Roles (for s3 access)\n",
    "            IamRoles=[roleArn],\n",
    "            #VpcSecurityGroupIds=[cluster_sg_id]\n",
    "        )\n",
    "except ClientError as e:\n",
    "        print(f'ERROR: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available now!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "        response1 = redshift.describe_clusters(ClusterIdentifier=CLUSTER_IDENTIFIER)\n",
    "        cluster_info = response1['Clusters'][0]\n",
    "        if cluster_info['ClusterStatus'] == 'available':\n",
    "            print(\"Available now!\")\n",
    "            break\n",
    "        time.sleep(10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  dwhcluster.cb8na8zcjnol.us-east-1.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::780041522191:role/Sparkify_DWH\n"
     ]
    }
   ],
   "source": [
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "#prettyRedshiftProps(myClusterProps)\n",
    "\n",
    "endpoint = myClusterProps['Endpoint']['Address']\n",
    "roleArn = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print(\"DWH_ENDPOINT :: \", endpoint)\n",
    "print(\"DWH_ROLE_ARN :: \", roleArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-065a259bed303ead7')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName='default',\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DB_PORT),\n",
    "        ToPort=int(DB_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dwhuser:Wachtwo0rd@dwhcluster.cb8na8zcjnol.us-east-1.redshift.amazonaws.com:5439/dwh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: dwhuser@dwh'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DB_USER, DB_PASSWORD, endpoint, DB_PORT,DB_NAME)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'dwhcluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'DBName': 'dwh',\n",
       "  'Endpoint': {'Address': 'dwhcluster.cb8na8zcjnol.us-east-1.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2020, 3, 13, 23, 24, 59, 918000, tzinfo=tzlocal()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-ff211e88',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-9571baee',\n",
       "  'AvailabilityZone': 'us-east-1f',\n",
       "  'PreferredMaintenanceWindow': 'tue:05:00-tue:05:30',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 4,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::780041522191:role/Sparkify_DWH',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current'},\n",
       " 'ResponseMetadata': {'RequestId': '2502b6b7-6582-11ea-9d6d-070c0825831c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '2502b6b7-6582-11ea-9d6d-070c0825831c',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2387',\n",
       "   'vary': 'Accept-Encoding',\n",
       "   'date': 'Fri, 13 Mar 2020 23:27:02 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "redshift.delete_cluster( ClusterIdentifier=CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)\n",
    "#### CAREFUL!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#myClusterProps\n",
    "while True:\n",
    "    try:\n",
    "        #myClusterProps = redshift.describe_clusters(ClusterIdentifier=CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "        response1 = redshift.describe_clusters(ClusterIdentifier=CLUSTER_IDENTIFIER)\n",
    "        cluster_info = response1['Clusters'][0]\n",
    "        time.sleep(10)\n",
    "    except:\n",
    "        \n",
    "            \n",
    "        print(\"Deleted!\")\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'e3924c1f-e267-4339-9fe0-9f03a3794729',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'e3924c1f-e267-4339-9fe0-9f03a3794729',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '200',\n",
       "   'date': 'Fri, 13 Mar 2020 23:28:48 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iam.detach_role_policy(RoleName=IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=IAM_ROLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
